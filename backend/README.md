# AIOS Backend - Sistema de An√°lise e Intelig√™ncia Operacional v2.0

Backend robusto e escal√°vel para a plataforma AIOS, constru√≠do com FastAPI, PostgreSQL/TimescaleDB, Redis e Celery.

## üèóÔ∏è Arquitetura

### Stack Tecnol√≥gica

- **Framework:** FastAPI + Uvicorn (API REST e WebSockets)
- **Banco de Dados:** PostgreSQL + TimescaleDB (s√©ries temporais)
- **Cache/Message Broker:** Redis
- **Task Queue:** Celery + Celery Beat
- **Vis√£o Computacional:** OpenCV + PyTorch + YOLOv8
- **ORM:** SQLAlchemy + Alembic
- **Valida√ß√£o:** Pydantic
- **Autentica√ß√£o:** JWT + bcrypt

### Componentes Principais

```
backend/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ api/v1/endpoints/     # Routers FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ api/ws/              # WebSocket manager
‚îÇ   ‚îú‚îÄ‚îÄ core/                # Configura√ß√µes e seguran√ßa
‚îÇ   ‚îú‚îÄ‚îÄ crud/                # Opera√ß√µes de banco de dados
‚îÇ   ‚îú‚îÄ‚îÄ db/models/           # Modelos SQLAlchemy
‚îÇ   ‚îú‚îÄ‚îÄ schemas/             # Schemas Pydantic
‚îÇ   ‚îú‚îÄ‚îÄ services/            # L√≥gica de neg√≥cio
‚îÇ   ‚îú‚îÄ‚îÄ workers/             # Tasks Celery
‚îÇ   ‚îî‚îÄ‚îÄ vision/              # M√≥dulos de CV
‚îú‚îÄ‚îÄ docker-compose.yml       # Orquestra√ß√£o dos servi√ßos
‚îî‚îÄ‚îÄ requirements.txt         # Depend√™ncias Python
```

## üöÄ In√≠cio R√°pido

### Pr√©-requisitos

- Python 3.11+
- Docker & Docker Compose
- Git

### Configura√ß√£o com Docker (Recomendado)

1. **Clone e configure o ambiente:**
```bash
cd backend
cp .env.example .env
# Edite o arquivo .env conforme necess√°rio
```

2. **Inicie todos os servi√ßos:**
```bash
docker-compose up -d
```

3. **Verifique os servi√ßos:**
```bash
# Backend API
curl http://localhost:8000/health

# Documenta√ß√£o
open http://localhost:8000/docs

# Monitoramento Celery
open http://localhost:5555
```

### Configura√ß√£o Manual (Desenvolvimento)

1. **Crie ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

2. **Instale depend√™ncias:**
```bash
pip install -r requirements.txt
```

3. **Configure banco de dados:**
```bash
# Inicie PostgreSQL e Redis
docker-compose up -d postgres redis

# Execute migra√ß√µes
alembic upgrade head
```

4. **Inicie o servidor:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

5. **Inicie workers Celery (terminal separado):**
```bash
celery -A app.workers.tasks worker --loglevel=info
```

## üìä Banco de Dados

### Schema Principal

- **organizations** - Multi-tenancy
- **users** - Autentica√ß√£o e autoriza√ß√£o
- **devices** - Fleet Management
- **pipelines/pipeline_nodes/pipeline_edges** - Pipeline Builder
- **events** (Hypertable) - Eventos de alto n√≠vel
- **detections** (Hypertable) - Detec√ß√µes de objetos

### TimescaleDB

As tabelas `events` e `detections` s√£o configuradas como hypertables para otimiza√ß√£o de s√©ries temporais:

```sql
-- Pol√≠ticas de reten√ß√£o autom√°ticas
SELECT add_retention_policy('detections', INTERVAL '30 days');
SELECT add_retention_policy('events', INTERVAL '1 year');
```

## üîå API Endpoints

### Autentica√ß√£o
- `POST /api/v1/auth/login` - Login
- `POST /api/v1/auth/register` - Registro
- `GET /api/v1/auth/me` - Usu√°rio atual

### Fleet Management
- `GET /api/v1/fleet/` - Lista dispositivos
- `POST /api/v1/fleet/` - Criar dispositivo
- `PUT /api/v1/fleet/{id}/status` - Atualizar status
- `GET /api/v1/fleet/summary` - Resumo da frota

### Pipelines
- `GET /api/v1/pipelines/` - Lista pipelines
- `POST /api/v1/pipelines/` - Criar pipeline
- `POST /api/v1/pipelines/{id}/execute` - Executar pipeline

### Dashboard
- `GET /api/v1/dashboard/analytics` - Analytics
- `GET /api/v1/dashboard/events` - Eventos
- `GET /api/v1/dashboard/detections` - Detec√ß√µes

### WebSocket
- `ws://localhost:8000/api/v1/ws?token=JWT_TOKEN` - Real-time updates

## ‚ö° WebSocket Events

O sistema envia atualiza√ß√µes em tempo real via WebSocket:

```json
{
  "type": "device_status_update",
  "device_id": "uuid",
  "status": "ON|OFF|WARNING",
  "timestamp": 1234567890
}

{
  "type": "new_event",
  "event": {
    "id": "uuid",
    "event_type": "intrusion_detected",
    "severity": "critical"
  }
}

{
  "type": "pipeline_status_update",
  "pipeline_id": "uuid",
  "status": "active|inactive|error"
}
```

## üîß Configura√ß√£o de Ambiente

### Vari√°veis Principais (.env)

```env
# Database
POSTGRES_SERVER=localhost
POSTGRES_USER=aios
POSTGRES_PASSWORD=secure_password
POSTGRES_DB=aios_db

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# Security
SECRET_KEY=your-super-secret-key-here
ACCESS_TOKEN_EXPIRE_MINUTES=60

# Computer Vision
YOLO_MODEL_PATH=./models/yolov8n.pt
DETECTION_CONFIDENCE_THRESHOLD=0.5
```

## üîÑ Tasks Celery

### Tasks Principais

- **process_video_stream** - Processamento de v√≠deo
- **run_pipeline** - Execu√ß√£o de pipeline
- **cleanup_old_data** - Limpeza de dados antigos
- **check_device_health** - Verifica√ß√£o de sa√∫de dos dispositivos
- **send_notification** - Envio de notifica√ß√µes

### Tasks Peri√≥dicas

```python
# Configuradas no celery_app.py
celery_app.conf.beat_schedule = {
    "cleanup-old-detections": {
        "task": "app.workers.tasks.cleanup_old_data",
        "schedule": 86400.0,  # Di√°rio
    },
    "check-device-health": {
        "task": "app.workers.tasks.check_device_health", 
        "schedule": 300.0,  # A cada 5 minutos
    }
}
```

## üß™ Testes

```bash
# Executar testes
pytest

# Com coverage
pytest --cov=app tests/

# Testes espec√≠ficos
pytest tests/test_fleet.py -v
```

## üìà Monitoramento

### Health Checks

```bash
# API Health
curl http://localhost:8000/health

# Database
curl http://localhost:8000/api/v1/fleet/summary

# Redis
redis-cli ping

# Celery (via Flower)
open http://localhost:5555
```

### Logs

```bash
# Application logs
docker-compose logs -f backend

# Celery logs
docker-compose logs -f celery_worker

# Database logs
docker-compose logs -f postgres
```

## üîí Seguran√ßa

- JWT tokens com expira√ß√£o configur√°vel
- Hashing de senhas com bcrypt
- CORS configurado
- Rate limiting via Nginx
- Valida√ß√£o rigorosa com Pydantic
- Isolamento multi-tenant por organiza√ß√£o

## üö¢ Deploy em Produ√ß√£o

### Docker Swarm

```bash
# Inicializar swarm
docker swarm init

# Deploy stack
docker stack deploy -c docker-compose.prod.yml aios
```

### Kubernetes

```bash
# Aplicar manifests
kubectl apply -f k8s/

# Verificar pods
kubectl get pods -n aios
```

### Considera√ß√µes de Produ√ß√£o

1. **Vari√°veis de ambiente**: Use secrets management
2. **SSL/TLS**: Configure certificados
3. **Backup**: Automatize backup do PostgreSQL
4. **Escalabilidade**: Configure auto-scaling para workers
5. **Monitoramento**: Integre com Prometheus/Grafana

## üîç Troubleshooting

### Problemas Comuns

**Database connection error:**
```bash
# Verifique se PostgreSQL est√° rodando
docker-compose ps postgres

# Verifique logs
docker-compose logs postgres
```

**Celery workers n√£o processando:**
```bash
# Verifique Redis
redis-cli ping

# Reinicie workers
docker-compose restart celery_worker
```

**High memory usage:**
```bash
# Monitore recursos
docker stats

# Ajuste concorr√™ncia Celery
# Edite CELERY_WORKER_CONCURRENCY no .env
```

## üìö Documenta√ß√£o Adicional

- **API Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Flower (Celery)**: http://localhost:5555
- **Arquitetura Detalhada**: [Link para documenta√ß√£o completa]

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudan√ßas
4. Push para a branch
5. Abra um Pull Request

## üìÑ Licen√ßa

Este projeto est√° sob licen√ßa MIT. Veja [LICENSE](LICENSE) para detalhes.
